{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Airline Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>number</th>\n",
       "      <th>keyword</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tidy_Tweets</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>0-apologize, 1-rectify, 2-supportive/helpful, 3-appreciate, 4 - misc.</th>\n",
       "      <th>Rating</th>\n",
       "      <th>0-neg, 1-neu, 2-pos</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943430</td>\n",
       "      <td>65789</td>\n",
       "      <td>TT</td>\n",
       "      <td>Hi there  the best team to assist you is our ...</td>\n",
       "      <td>there best team assist contact centr fee appli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1.0, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.970177</td>\n",
       "      <td>49400</td>\n",
       "      <td>NK</td>\n",
       "      <td>We re awfully sorry to hear about that  Pleas...</td>\n",
       "      <td>aw sorri hear about that pleas your reserv inf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.5, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.143541</td>\n",
       "      <td>60959</td>\n",
       "      <td>TOM</td>\n",
       "      <td>RT   In #Namibia  Melissa and Anna Marie found...</td>\n",
       "      <td>#namibia melissa anna mari found immedi after ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360187</td>\n",
       "      <td>77607</td>\n",
       "      <td>VA</td>\n",
       "      <td>We re sorry to hear this Peter  We would reco...</td>\n",
       "      <td>sorri hear thi peter would recommend phone bag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.04999999999999999, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.779308</td>\n",
       "      <td>58487</td>\n",
       "      <td>TOM</td>\n",
       "      <td>RT   The Q  #TUIResults are out and show signi...</td>\n",
       "      <td>#tuiresult show signific growth custom number ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.375, 0.875)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.510298</td>\n",
       "      <td>15909</td>\n",
       "      <td>AS</td>\n",
       "      <td>I ll work on that for ya     Laura</td>\n",
       "      <td>work that laura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.703480</td>\n",
       "      <td>63020</td>\n",
       "      <td>TOM</td>\n",
       "      <td>RT   Tui Travel reports record results   pc ju...</td>\n",
       "      <td>travel report record result jump profit peter ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.05, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.085105</td>\n",
       "      <td>58046</td>\n",
       "      <td>TOM</td>\n",
       "      <td>#TUIresults in detail  focus on #cruises  Stro...</td>\n",
       "      <td>#tuiresult detail focu #cruis strong growth pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.5916666666666667, 0.8416666666666666)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.260572</td>\n",
       "      <td>42866</td>\n",
       "      <td>LH</td>\n",
       "      <td>Please advise your full name  email and posta...</td>\n",
       "      <td>pleas advis your full name email postal addres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.16499999999999998, 0.6599999999999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.299976</td>\n",
       "      <td>76133</td>\n",
       "      <td>UX</td>\n",
       "      <td>Hi Nicol s  Indicate us please your booking r...</td>\n",
       "      <td>nicol indic pleas your book refer privat help</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.375)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  number keyword  \\\n",
       "0      0.943430   65789      TT   \n",
       "1      0.970177   49400      NK   \n",
       "2      0.143541   60959     TOM   \n",
       "3      0.360187   77607      VA   \n",
       "4      0.779308   58487     TOM   \n",
       "..          ...     ...     ...   \n",
       "318    0.510298   15909      AS   \n",
       "319    0.703480   63020     TOM   \n",
       "320    0.085105   58046     TOM   \n",
       "321    0.260572   42866      LH   \n",
       "322    0.299976   76133      UX   \n",
       "\n",
       "                                                  Text  \\\n",
       "0     Hi there  the best team to assist you is our ...   \n",
       "1     We re awfully sorry to hear about that  Pleas...   \n",
       "2    RT   In #Namibia  Melissa and Anna Marie found...   \n",
       "3     We re sorry to hear this Peter  We would reco...   \n",
       "4    RT   The Q  #TUIResults are out and show signi...   \n",
       "..                                                 ...   \n",
       "318                 I ll work on that for ya     Laura   \n",
       "319  RT   Tui Travel reports record results   pc ju...   \n",
       "320  #TUIresults in detail  focus on #cruises  Stro...   \n",
       "321   Please advise your full name  email and posta...   \n",
       "322   Hi Nicol s  Indicate us please your booking r...   \n",
       "\n",
       "                                           Tidy_Tweets  Unnamed: 5  \\\n",
       "0    there best team assist contact centr fee appli...         NaN   \n",
       "1    aw sorri hear about that pleas your reserv inf...         NaN   \n",
       "2    #namibia melissa anna mari found immedi after ...         NaN   \n",
       "3    sorri hear thi peter would recommend phone bag...         NaN   \n",
       "4    #tuiresult show signific growth custom number ...         NaN   \n",
       "..                                                 ...         ...   \n",
       "318                                    work that laura         NaN   \n",
       "319  travel report record result jump profit peter ...         NaN   \n",
       "320  #tuiresult detail focu #cruis strong growth pa...         NaN   \n",
       "321  pleas advis your full name email postal addres...         NaN   \n",
       "322      nicol indic pleas your book refer privat help         NaN   \n",
       "\n",
       "     0-apologize, 1-rectify, 2-supportive/helpful, 3-appreciate, 4 - misc.  \\\n",
       "0                                                  NaN                       \n",
       "1                                                    -                       \n",
       "2                                                  NaN                       \n",
       "3                                                  NaN                       \n",
       "4                                                  NaN                       \n",
       "..                                                 ...                       \n",
       "318                                                NaN                       \n",
       "319                                                NaN                       \n",
       "320                                                NaN                       \n",
       "321                                                NaN                       \n",
       "322                                                NaN                       \n",
       "\n",
       "    Rating 0-neg, 1-neu, 2-pos                                  sentiment  \n",
       "0        H                 NaN                                 (1.0, 0.3)  \n",
       "1        U                 NaN                                (-0.5, 1.0)  \n",
       "2        N                 NaN                                 (0.0, 0.0)  \n",
       "3        U                 NaN                (-0.04999999999999999, 0.7)  \n",
       "4        N                 NaN                             (0.375, 0.875)  \n",
       "..     ...                 ...                                        ...  \n",
       "318      H                 NaN                                 (0.0, 0.0)  \n",
       "319      N                 NaN                               (-0.05, 0.4)  \n",
       "320      N                 NaN   (0.5916666666666667, 0.8416666666666666)  \n",
       "321      H                 NaN  (0.16499999999999998, 0.6599999999999999)  \n",
       "322      H                 NaN                               (0.0, 0.375)  \n",
       "\n",
       "[323 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Textblob sentiment analysis\n",
    "Code was used from:\n",
    "https://towardsdatascience.com/having-fun-with-textblob-7e9eed783d3f\n",
    "https://stackoverflow.com/questions/43485469/apply-textblob-in-for-each-row-of-a-dataframe\n",
    "'''\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "#replace null values with empty space\n",
    "noNull = df['Text'].fillna(\"\")\n",
    "\n",
    "df['sentiment'] = noNull.apply(lambda tweet: TextBlob(tweet).sentiment)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Karthik\n",
      "[nltk_data]     Doddi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>number</th>\n",
       "      <th>keyword</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tidy_Tweets</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>0-apologize, 1-rectify, 2-supportive/helpful, 3-appreciate, 4 - misc.</th>\n",
       "      <th>Rating</th>\n",
       "      <th>0-neg, 1-neu, 2-pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943430</td>\n",
       "      <td>65789</td>\n",
       "      <td>TT</td>\n",
       "      <td>Hi there  the best team to assist you is our ...</td>\n",
       "      <td>there best team assist contact centr fee appli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1.0, 0.3)</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.970177</td>\n",
       "      <td>49400</td>\n",
       "      <td>NK</td>\n",
       "      <td>We re awfully sorry to hear about that  Pleas...</td>\n",
       "      <td>aw sorri hear about that pleas your reserv inf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.5, 1.0)</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.143541</td>\n",
       "      <td>60959</td>\n",
       "      <td>TOM</td>\n",
       "      <td>RT   In #Namibia  Melissa and Anna Marie found...</td>\n",
       "      <td>#namibia melissa anna mari found immedi after ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360187</td>\n",
       "      <td>77607</td>\n",
       "      <td>VA</td>\n",
       "      <td>We re sorry to hear this Peter  We would reco...</td>\n",
       "      <td>sorri hear thi peter would recommend phone bag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.04999999999999999, 0.7)</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.779308</td>\n",
       "      <td>58487</td>\n",
       "      <td>TOM</td>\n",
       "      <td>RT   The Q  #TUIResults are out and show signi...</td>\n",
       "      <td>#tuiresult show signific growth custom number ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.375, 0.875)</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.510298</td>\n",
       "      <td>15909</td>\n",
       "      <td>AS</td>\n",
       "      <td>I ll work on that for ya     Laura</td>\n",
       "      <td>work that laura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.703480</td>\n",
       "      <td>63020</td>\n",
       "      <td>TOM</td>\n",
       "      <td>RT   Tui Travel reports record results   pc ju...</td>\n",
       "      <td>travel report record result jump profit peter ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.05, 0.4)</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.085105</td>\n",
       "      <td>58046</td>\n",
       "      <td>TOM</td>\n",
       "      <td>#TUIresults in detail  focus on #cruises  Stro...</td>\n",
       "      <td>#tuiresult detail focu #cruis strong growth pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.5916666666666667, 0.8416666666666666)</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.8442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.260572</td>\n",
       "      <td>42866</td>\n",
       "      <td>LH</td>\n",
       "      <td>Please advise your full name  email and posta...</td>\n",
       "      <td>pleas advis your full name email postal addres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.16499999999999998, 0.6599999999999999)</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.299976</td>\n",
       "      <td>76133</td>\n",
       "      <td>UX</td>\n",
       "      <td>Hi Nicol s  Indicate us please your booking r...</td>\n",
       "      <td>nicol indic pleas your book refer privat help</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.375)</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  number keyword  \\\n",
       "0      0.943430   65789      TT   \n",
       "1      0.970177   49400      NK   \n",
       "2      0.143541   60959     TOM   \n",
       "3      0.360187   77607      VA   \n",
       "4      0.779308   58487     TOM   \n",
       "..          ...     ...     ...   \n",
       "318    0.510298   15909      AS   \n",
       "319    0.703480   63020     TOM   \n",
       "320    0.085105   58046     TOM   \n",
       "321    0.260572   42866      LH   \n",
       "322    0.299976   76133      UX   \n",
       "\n",
       "                                                  Text  \\\n",
       "0     Hi there  the best team to assist you is our ...   \n",
       "1     We re awfully sorry to hear about that  Pleas...   \n",
       "2    RT   In #Namibia  Melissa and Anna Marie found...   \n",
       "3     We re sorry to hear this Peter  We would reco...   \n",
       "4    RT   The Q  #TUIResults are out and show signi...   \n",
       "..                                                 ...   \n",
       "318                 I ll work on that for ya     Laura   \n",
       "319  RT   Tui Travel reports record results   pc ju...   \n",
       "320  #TUIresults in detail  focus on #cruises  Stro...   \n",
       "321   Please advise your full name  email and posta...   \n",
       "322   Hi Nicol s  Indicate us please your booking r...   \n",
       "\n",
       "                                           Tidy_Tweets  Unnamed: 5  \\\n",
       "0    there best team assist contact centr fee appli...         NaN   \n",
       "1    aw sorri hear about that pleas your reserv inf...         NaN   \n",
       "2    #namibia melissa anna mari found immedi after ...         NaN   \n",
       "3    sorri hear thi peter would recommend phone bag...         NaN   \n",
       "4    #tuiresult show signific growth custom number ...         NaN   \n",
       "..                                                 ...         ...   \n",
       "318                                    work that laura         NaN   \n",
       "319  travel report record result jump profit peter ...         NaN   \n",
       "320  #tuiresult detail focu #cruis strong growth pa...         NaN   \n",
       "321  pleas advis your full name email postal addres...         NaN   \n",
       "322      nicol indic pleas your book refer privat help         NaN   \n",
       "\n",
       "     0-apologize, 1-rectify, 2-supportive/helpful, 3-appreciate, 4 - misc.  \\\n",
       "0                                                  NaN                       \n",
       "1                                                    -                       \n",
       "2                                                  NaN                       \n",
       "3                                                  NaN                       \n",
       "4                                                  NaN                       \n",
       "..                                                 ...                       \n",
       "318                                                NaN                       \n",
       "319                                                NaN                       \n",
       "320                                                NaN                       \n",
       "321                                                NaN                       \n",
       "322                                                NaN                       \n",
       "\n",
       "    Rating 0-neg, 1-neu, 2-pos                                  sentiment  \\\n",
       "0        H                 NaN                                 (1.0, 0.3)   \n",
       "1        U                 NaN                                (-0.5, 1.0)   \n",
       "2        N                 NaN                                 (0.0, 0.0)   \n",
       "3        U                 NaN                (-0.04999999999999999, 0.7)   \n",
       "4        N                 NaN                             (0.375, 0.875)   \n",
       "..     ...                 ...                                        ...   \n",
       "318      H                 NaN                                 (0.0, 0.0)   \n",
       "319      N                 NaN                               (-0.05, 0.4)   \n",
       "320      N                 NaN   (0.5916666666666667, 0.8416666666666666)   \n",
       "321      H                 NaN  (0.16499999999999998, 0.6599999999999999)   \n",
       "322      H                 NaN                               (0.0, 0.375)   \n",
       "\n",
       "     Positive  Negative  Neutral  Compound  \n",
       "0       0.174     0.000    0.826    0.6369  \n",
       "1       0.096     0.067    0.837    0.1796  \n",
       "2       0.000     0.000    1.000    0.0000  \n",
       "3       0.066     0.034    0.899    0.2960  \n",
       "4       0.180     0.000    0.820    0.5267  \n",
       "..        ...       ...      ...       ...  \n",
       "318     0.000     0.000    1.000    0.0000  \n",
       "319     0.116     0.000    0.884    0.4404  \n",
       "320     0.431     0.000    0.569    0.8442  \n",
       "321     0.120     0.000    0.880    0.6124  \n",
       "322     0.263     0.000    0.737    0.6124  \n",
       "\n",
       "[323 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Vader from nltk for sentiment analysis\n",
    "Code was used from:\n",
    "http://www.nltk.org/howto/sentiment.html\n",
    "https://stackoverflow.com/questions/57803412/applying-sentimentintensityanalyzer-function-on-each-row-of-the-dataframe-prov\n",
    "http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html\n",
    "https://stackoverflow.com/questions/52323299/python-return-elif-statement\n",
    "'''\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon') #download if don't have vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "def get_sentiment(row, **kwargs):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = sid.polarity_scores(row)\n",
    "    positive_meter = sentiment_score['pos']\n",
    "    negative_meter = sentiment_score['neg']\n",
    "    neutral_meter = sentiment_score['neu']\n",
    "    compound_meter = sentiment_score['compound']\n",
    "    \n",
    "    if kwargs['k'] == 'positive':\n",
    "        return positive_meter\n",
    "    elif kwargs['k'] == 'negative':\n",
    "        return negative_meter\n",
    "    elif kwargs['k'] == 'neutral':\n",
    "        return neutral_meter\n",
    "    else:\n",
    "        return compound_meter\n",
    "\n",
    "#replace null values with empty space\n",
    "noNull = df['Text'].fillna(\"\")\n",
    "\n",
    "#tokenize tweets\n",
    "tokenized_tweet = noNull.apply(lambda x: x.split())\n",
    "\n",
    "#put list back together\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "\n",
    "df['Positive'] = tokenized_tweet.apply(get_sentiment, k= 'positive')\n",
    "df['Negative'] = tokenized_tweet.apply(get_sentiment, k= 'negative')\n",
    "df['Neutral'] = tokenized_tweet.apply(get_sentiment, k = 'neutral')\n",
    "df['Compound'] = tokenized_tweet.apply(get_sentiment, k = 'compound')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "##Cross Validation\n",
    "\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "\n",
    "X=np.array(df['Text'])\n",
    "y=np.array(df['Rating'])\n",
    "\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Train & Run the model\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 1)\n",
    "vectorizer = TfidfVectorizer(min_df=15)\n",
    "def run_model(model,modelType):\n",
    "    scores=list()\n",
    "    scores_std=list()\n",
    "    C_s = np.logspace(-10, 0, 10)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        if modelType == \"KNN\":\n",
    "            #vectorizer = TfidfVectorizer(min_df=15)\n",
    "            X_train_dtm = vectorizer.fit_transform(X_train)\n",
    "            X_test_dtm = vectorizer.transform(X_test)\n",
    "            \n",
    "        else:\n",
    "            #vect = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 1)\n",
    "            #Using training data to transform text into counts of features for each message\n",
    "            vect.fit(X_train)\n",
    "            X_train_dtm = vect.transform(X_train) \n",
    "            X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "        #Fit Model\n",
    "        model.fit(X_train_dtm, y_train)\n",
    "        y_pred = model.predict(X_test_dtm)\n",
    "\n",
    "        this_scores=metrics.accuracy_score(y_test,y_pred)*100\n",
    "        scores.append(np.mean(this_scores))\n",
    "        scores_std.append(np.std(this_scores))\n",
    "        \n",
    "        print('Accuracy Score: ',this_scores,'%',sep='')\n",
    "        print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 78.78787878787878%\n",
      "Confusion Matrix: \n",
      "[[10  0  2]\n",
      " [ 1  6  1]\n",
      " [ 1  2 10]]\n",
      "Accuracy Score: 51.515151515151516%\n",
      "Confusion Matrix: \n",
      "[[7 4 1]\n",
      " [4 2 2]\n",
      " [3 2 8]]\n",
      "Accuracy Score: 66.66666666666666%\n",
      "Confusion Matrix: \n",
      "[[10  2  0]\n",
      " [ 2  3  3]\n",
      " [ 4  0  9]]\n",
      "Accuracy Score: 65.625%\n",
      "Confusion Matrix: \n",
      "[[10  4  2]\n",
      " [ 1  3  0]\n",
      " [ 3  1  8]]\n",
      "Accuracy Score: 56.25%\n",
      "Confusion Matrix: \n",
      "[[7 3 3]\n",
      " [2 3 1]\n",
      " [3 2 8]]\n",
      "Accuracy Score: 78.125%\n",
      "Confusion Matrix: \n",
      "[[14  2  3]\n",
      " [ 1  6  0]\n",
      " [ 1  0  5]]\n",
      "Accuracy Score: 65.625%\n",
      "Confusion Matrix: \n",
      "[[5 4 2]\n",
      " [1 7 0]\n",
      " [3 1 9]]\n",
      "Accuracy Score: 65.625%\n",
      "Confusion Matrix: \n",
      "[[8 1 5]\n",
      " [3 4 0]\n",
      " [1 1 9]]\n",
      "Accuracy Score: 62.5%\n",
      "Confusion Matrix: \n",
      "[[10  1  5]\n",
      " [ 3  4  0]\n",
      " [ 1  2  6]]\n",
      "Accuracy Score: 71.875%\n",
      "Confusion Matrix: \n",
      "[[ 9  2  3]\n",
      " [ 1  4  1]\n",
      " [ 2  0 10]]\n",
      "\n",
      "K Nearest Neighbors (NN = 1)\n",
      "Accuracy Score: 66.2594696969697%\n"
     ]
    }
   ],
   "source": [
    "'''KNN model'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#KNN Classifiers\n",
    "KNN = KNeighborsClassifier(n_neighbors = 1)\n",
    "scores=run_model(KNN,\"KNN\")\n",
    "\n",
    "print('\\nK Nearest Neighbors (NN = 1)')\n",
    "print('Accuracy Score: ',np.mean(scores),'%',sep='')\n",
    "#print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 87.87878787878788%\n",
      "Confusion Matrix: \n",
      "[[11  0  1]\n",
      " [ 2  6  0]\n",
      " [ 1  0 12]]\n",
      "Accuracy Score: 78.78787878787878%\n",
      "Confusion Matrix: \n",
      "[[11  1  0]\n",
      " [ 3  5  0]\n",
      " [ 2  1 10]]\n",
      "Accuracy Score: 75.75757575757575%\n",
      "Confusion Matrix: \n",
      "[[10  2  0]\n",
      " [ 2  5  1]\n",
      " [ 3  0 10]]\n",
      "Accuracy Score: 90.625%\n",
      "Confusion Matrix: \n",
      "[[14  2  0]\n",
      " [ 1  3  0]\n",
      " [ 0  0 12]]\n",
      "Accuracy Score: 84.375%\n",
      "Confusion Matrix: \n",
      "[[11  2  0]\n",
      " [ 2  4  0]\n",
      " [ 1  0 12]]\n",
      "Accuracy Score: 87.5%\n",
      "Confusion Matrix: \n",
      "[[17  1  1]\n",
      " [ 1  6  0]\n",
      " [ 1  0  5]]\n",
      "Accuracy Score: 87.5%\n",
      "Confusion Matrix: \n",
      "[[10  1  0]\n",
      " [ 2  6  0]\n",
      " [ 1  0 12]]\n",
      "Accuracy Score: 90.625%\n",
      "Confusion Matrix: \n",
      "[[14  0  0]\n",
      " [ 0  7  0]\n",
      " [ 1  2  8]]\n",
      "Accuracy Score: 78.125%\n",
      "Confusion Matrix: \n",
      "[[12  3  1]\n",
      " [ 2  5  0]\n",
      " [ 1  0  8]]\n",
      "Accuracy Score: 96.875%\n",
      "Confusion Matrix: \n",
      "[[13  1  0]\n",
      " [ 0  6  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy Score: 85.80492424242424%\n"
     ]
    }
   ],
   "source": [
    "'''Logistic Regression'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#logistic regression\n",
    "LR = LogisticRegression()\n",
    "scores=run_model(LR,\"LR\")\n",
    "\n",
    "print('\\nLogistic Regression')\n",
    "print('Accuracy Score: ',np.mean(scores),'%',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 75.75757575757575%\n",
      "Confusion Matrix: \n",
      "[[ 9  1  2]\n",
      " [ 2  6  0]\n",
      " [ 3  0 10]]\n",
      "Accuracy Score: 75.75757575757575%\n",
      "Confusion Matrix: \n",
      "[[10  2  0]\n",
      " [ 3  5  0]\n",
      " [ 2  1 10]]\n",
      "Accuracy Score: 81.81818181818183%\n",
      "Confusion Matrix: \n",
      "[[10  2  0]\n",
      " [ 1  6  1]\n",
      " [ 2  0 11]]\n",
      "Accuracy Score: 87.5%\n",
      "Confusion Matrix: \n",
      "[[13  2  1]\n",
      " [ 1  3  0]\n",
      " [ 0  0 12]]\n",
      "Accuracy Score: 81.25%\n",
      "Confusion Matrix: \n",
      "[[ 9  4  0]\n",
      " [ 1  5  0]\n",
      " [ 1  0 12]]\n",
      "Accuracy Score: 81.25%\n",
      "Confusion Matrix: \n",
      "[[15  3  1]\n",
      " [ 1  6  0]\n",
      " [ 1  0  5]]\n",
      "Accuracy Score: 84.375%\n",
      "Confusion Matrix: \n",
      "[[ 9  1  1]\n",
      " [ 2  6  0]\n",
      " [ 1  0 12]]\n",
      "Accuracy Score: 90.625%\n",
      "Confusion Matrix: \n",
      "[[14  0  0]\n",
      " [ 0  7  0]\n",
      " [ 1  2  8]]\n",
      "Accuracy Score: 81.25%\n",
      "Confusion Matrix: \n",
      "[[12  3  1]\n",
      " [ 1  6  0]\n",
      " [ 1  0  8]]\n",
      "Accuracy Score: 93.75%\n",
      "Confusion Matrix: \n",
      "[[12  1  1]\n",
      " [ 0  6  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "Support Vector Machine\n",
      "Accuracy Score: 83.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "'''Support Vector Machine'''\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#SVM\n",
    "SVM = LinearSVC(penalty='l2', loss='squared_hinge')\n",
    "#kernel = 'linear', random_state = 0\n",
    "\n",
    "scores=run_model(SVM,\"SVM\")\n",
    "print('\\nSupport Vector Machine')\n",
    "print('Accuracy Score: ',np.mean(scores),'%',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 69.6969696969697%\n",
      "Confusion Matrix: \n",
      "[[11  0  1]\n",
      " [ 6  2  0]\n",
      " [ 3  0 10]]\n",
      "Accuracy Score: 72.72727272727273%\n",
      "Confusion Matrix: \n",
      "[[10  1  1]\n",
      " [ 5  3  0]\n",
      " [ 0  2 11]]\n",
      "Accuracy Score: 60.60606060606061%\n",
      "Confusion Matrix: \n",
      "[[11  0  1]\n",
      " [ 7  1  0]\n",
      " [ 5  0  8]]\n",
      "Accuracy Score: 78.125%\n",
      "Confusion Matrix: \n",
      "[[11  3  2]\n",
      " [ 1  3  0]\n",
      " [ 1  0 11]]\n",
      "Accuracy Score: 65.625%\n",
      "Confusion Matrix: \n",
      "[[10  0  3]\n",
      " [ 4  1  1]\n",
      " [ 3  0 10]]\n",
      "Accuracy Score: 59.375%\n",
      "Confusion Matrix: \n",
      "[[10  4  5]\n",
      " [ 1  5  1]\n",
      " [ 2  0  4]]\n",
      "Accuracy Score: 78.125%\n",
      "Confusion Matrix: \n",
      "[[11  0  0]\n",
      " [ 7  1  0]\n",
      " [ 0  0 13]]\n",
      "Accuracy Score: 78.125%\n",
      "Confusion Matrix: \n",
      "[[12  2  0]\n",
      " [ 0  7  0]\n",
      " [ 3  2  6]]\n",
      "Accuracy Score: 87.5%\n",
      "Confusion Matrix: \n",
      "[[16  0  0]\n",
      " [ 4  3  0]\n",
      " [ 0  0  9]]\n",
      "Accuracy Score: 68.75%\n",
      "Confusion Matrix: \n",
      "[[9 5 0]\n",
      " [0 6 0]\n",
      " [5 0 7]]\n",
      "\n",
      " Random Forest Classifier\n",
      "Accuracy Score: 71.8655303030303%\n"
     ]
    }
   ],
   "source": [
    "'''Random Forest Classifier'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators = 3,random_state=0)\n",
    "scores=run_model(RFC,\"RFC\")\n",
    "\n",
    "print('\\n Random Forest Classifier')\n",
    "print('Accuracy Score: ',np.mean(scores),'%',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 87.87878787878788%\n",
      "Confusion Matrix: \n",
      "[[11  0  1]\n",
      " [ 2  5  1]\n",
      " [ 0  0 13]]\n",
      "Accuracy Score: 66.66666666666666%\n",
      "Confusion Matrix: \n",
      "[[ 9  0  3]\n",
      " [ 4  2  2]\n",
      " [ 1  1 11]]\n",
      "Accuracy Score: 60.60606060606061%\n",
      "Confusion Matrix: \n",
      "[[ 7  1  4]\n",
      " [ 3  2  3]\n",
      " [ 2  0 11]]\n",
      "Accuracy Score: 75.0%\n",
      "Confusion Matrix: \n",
      "[[ 9  0  7]\n",
      " [ 1  3  0]\n",
      " [ 0  0 12]]\n",
      "Accuracy Score: 81.25%\n",
      "Confusion Matrix: \n",
      "[[11  0  2]\n",
      " [ 3  2  1]\n",
      " [ 0  0 13]]\n",
      "Accuracy Score: 65.625%\n",
      "Confusion Matrix: \n",
      "[[13  1  5]\n",
      " [ 1  2  4]\n",
      " [ 0  0  6]]\n",
      "Accuracy Score: 78.125%\n",
      "Confusion Matrix: \n",
      "[[10  0  1]\n",
      " [ 5  2  1]\n",
      " [ 0  0 13]]\n",
      "Accuracy Score: 87.5%\n",
      "Confusion Matrix: \n",
      "[[12  0  2]\n",
      " [ 0  6  1]\n",
      " [ 1  0 10]]\n",
      "Accuracy Score: 62.5%\n",
      "Confusion Matrix: \n",
      "[[10  0  6]\n",
      " [ 1  2  4]\n",
      " [ 1  0  8]]\n",
      "Accuracy Score: 90.625%\n",
      "Confusion Matrix: \n",
      "[[14  0  0]\n",
      " [ 2  3  1]\n",
      " [ 0  0 12]]\n",
      "\n",
      "Naive Bayes\n",
      "Accuracy Score: 75.57765151515152%\n"
     ]
    }
   ],
   "source": [
    "'''Naive Bayes Model'''\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Naive Bayes Model\n",
    "NB = MultinomialNB()\n",
    "scores=run_model(NB,\"NB\")\n",
    "\n",
    "print('\\nNaive Bayes')\n",
    "print('Accuracy Score: ',np.mean(scores),'%',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
